{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10: Recommender System\n",
    "\n",
    "In this assignment, we will study how to do user-based collaborative filtering and item-based collaborative filtering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "In this assignment, we will use MovieLens-100K dataset. It includes about 100,000 ratings from 1000 users on 1700 movies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1664)\n",
      "(943, 1664)\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "# 1. load data\n",
    "user_ratings_train = pd.read_csv('./ml-100k/u1.base',\n",
    "                            sep='\\t',names=['user_id','movie_id','rating'], usecols=[0,1,2])\n",
    "\n",
    "user_ratings_test = pd.read_csv('./ml-100k/u1.test',\n",
    "                            sep='\\t',names=['user_id','movie_id','rating'], usecols=[0,1,2])\n",
    "\n",
    "movie_info =  pd.read_csv('./ml-100k/u.item', \n",
    "                          sep='|', names=['movie_id','title'], usecols=[0,1],\n",
    "                          encoding=\"ISO-8859-1\")\n",
    "\n",
    "user_ratings_train = pd.merge(movie_info, user_ratings_train)\n",
    "user_ratings_test = pd.merge(movie_info, user_ratings_test)\n",
    "\n",
    "# 2. get the rating matrix. Each row is a user, and each column is a movie.\n",
    "user_ratings_train = user_ratings_train.pivot_table(index=['user_id'],\n",
    "                                        columns=['title'],\n",
    "                                        values='rating')\n",
    "\n",
    "user_ratings_test = user_ratings_test.pivot_table(index=['user_id'],\n",
    "                                        columns=['title'],\n",
    "                                        values='rating')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "user_ratings_train = user_ratings_train.reindex(\n",
    "                            index=user_ratings_train.index.union(user_ratings_test.index), \n",
    "                            columns=user_ratings_train.columns.union(user_ratings_test.columns) )\n",
    "\n",
    "user_ratings_test = user_ratings_test.reindex(\n",
    "                            index=user_ratings_train.index.union(user_ratings_test.index), \n",
    "                            columns=user_ratings_train.columns.union(user_ratings_test.columns) )\n",
    "\n",
    "print(user_ratings_train.shape)\n",
    "print(user_ratings_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. User-based CF\n",
    "\n",
    "* Use pearson correlation to get the similarity between different users.\n",
    "* Based on the obtained similarity score, predict the ratings. You can use 5 nearest neighbors or 10 nearest neighbors.\n",
    "* Compute MAE for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.06023134 0.02175852 ... 0.17022618 0.13475539 0.08277204]\n",
      " [0.06023134 1.         0.03406568 ... 0.15924813 0.11801274 0.09905043]\n",
      " [0.02175852 0.03406568 1.         ... 0.10870144 0.07108757 0.05824196]\n",
      " ...\n",
      " [0.17022618 0.15924813 0.10870144 ... 1.         0.12222343 0.22341614]\n",
      " [0.13475539 0.11801274 0.07108757 ... 0.12222343 1.         0.08091865]\n",
      " [0.08277204 0.09905043 0.05824196 ... 0.22341614 0.08091865 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "import math\n",
    "user_ratings_train = user_ratings_train.fillna(0)\n",
    "user_ratings_test = user_ratings_test.fillna(0)\n",
    "\n",
    "train_mean = user_ratings_train.mean(axis=1)\n",
    "test_mean = user_ratings_test.mean(axis=1) \n",
    "\n",
    "train_means_expanded = np.outer(train_mean, np.ones(1664))\n",
    "test_means_expanded = np.outer(test_mean, np.ones(1664))\n",
    "\n",
    "train_means_subtracted = user_ratings_train - train_means_expanded\n",
    "test_means_subtracted = user_ratings_test - test_means_expanded\n",
    "#print(test_means_subtracted)\n",
    "similarity = []\n",
    "similarities = np.zeros((942,942))\n",
    "\n",
    "\n",
    "for i in range(1, 943):\n",
    "    denominator_i = train_means_subtracted.loc[i]\n",
    "    denominator_i = np.square(denominator_i)\n",
    "    denominator_i = denominator_i.sum()\n",
    "    denominator_i = math.sqrt(denominator_i)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for j in range(1, 943):\n",
    "        numerator = train_means_subtracted.loc[i] * train_means_subtracted.loc[j]\n",
    "        numerator = numerator.sum()\n",
    "\n",
    "        denominator_j = np.square(train_means_subtracted.loc[j])\n",
    "        denominator_j = denominator_j.sum()\n",
    "        denominator_j = math.sqrt(denominator_j)\n",
    "\n",
    "        denominator = denominator_j * denominator_i\n",
    "\n",
    "        similarity.append((numerator / denominator))\n",
    "        \n",
    "    similarities[i-1] = similarity\n",
    "    similarity = []\n",
    "\n",
    "print(similarities)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = user_ratings_train.to_numpy()\n",
    "numerator = 0\n",
    "denominator = 0\n",
    "predicted_scores = np.zeros((942,1664))\n",
    "#train_means_subtracted = train_means_subtracted.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, 942):\n",
    "    for j in range(0, 1664):\n",
    "        if (temp[i][j] != 0):\n",
    "\n",
    "            continue\n",
    "        else:\n",
    "            for k in range(0, 942):\n",
    "                if (temp[k][j] == 0 or k == i):\n",
    "                    continue\n",
    "                else:\n",
    "                    numerator = numerator + (train_means_subtracted[k][j] * similarities[i][k])\n",
    "                    denominator = denominator + (similarities[i][k])\n",
    "                    \n",
    "            if (denominator != 0):\n",
    "                score = numerator / denominator\n",
    "                predicted_scores[i][j] = score\n",
    "            else:\n",
    "                predicted_scores[i][j] = 0\n",
    "   \n",
    "print(predicted_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Item-based CF\n",
    "* Use cosine similarity to get the similarity between different items.\n",
    "* Based on the obtained similarity score, predict the ratings. You can use 5 nearest neighbors or 10 nearest neighbors.\n",
    "* Compute MAE for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
